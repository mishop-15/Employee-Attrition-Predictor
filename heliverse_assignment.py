# -*- coding: utf-8 -*-
"""Heliverse_Assignment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iFySbfRH73T5GnP8dC3jWcxLTArsUejU
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
from sklearn.metrics import roc_curve, auc
from sklearn.model_selection import GridSearchCV
from plotnine import ggplot, aes, geom_bar, labs, theme, element_text, stats
import pickle
import warnings
warnings.filterwarnings('ignore')

df = pd.read_csv('IBM_HR.csv')

df.head()

df.info()

df.isnull().sum()

df.describe()

"""Visualizing the Dataset for better understanding"""

def plot_categorical_data(data, categorical_features, nrows, ncols, figsize=(15, 10), hspace=0.4, wspace=0.4):
    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize)
    fig.subplots_adjust(hspace=hspace, wspace=wspace)
    axes = axes.ravel()

    for i, cat_feature in enumerate(categorical_features):
        ax = axes[i]
        categories = data[cat_feature].value_counts().index
        counts = data[cat_feature].value_counts().values
        ax.barh(categories, counts)
        ax.set_title(cat_feature)
        ax.set_xlabel('Count')

    for j in range(i + 1, nrows * ncols):
        fig.delaxes(axes[j])

    plt.tight_layout()
    plt.show()


categorical_features = ['Attrition', 'BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus', 'Over18', 'OverTime']
plot_categorical_data(df, categorical_features, nrows=3, ncols=3)

def plot_numerical_data(data, numerical_features, nrows, ncols, figsize=(15, 10), hspace=0.4, wspace=0.4):
    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize)
    fig.subplots_adjust(hspace=hspace, wspace=wspace)
    axes = axes.ravel()

    for i, num_feature in enumerate(numerical_features):
        ax = axes[i]
        ax.hist(data[num_feature], bins=20, color='skyblue', edgecolor='black')
        ax.set_title(num_feature)
        ax.set_xlabel('Value')
        ax.set_ylabel('Frequency')

    for j in range(i + 1, nrows * ncols):
        fig.delaxes(axes[j])

    plt.tight_layout()
    plt.show()

numerical_features = ['Age', 'DailyRate', 'DistanceFromHome', 'Education', 'HourlyRate', 'MonthlyIncome', 'NumCompaniesWorked', 'PercentSalaryHike', 'PerformanceRating', 'RelationshipSatisfaction', 'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance', 'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager']
plot_numerical_data(df, numerical_features, nrows=3, ncols=6)

def plot_categorical_percentage(df, column):
    counts = df[column].value_counts()
    percentages = counts / counts.sum() * 100

    plt.figure(figsize=(10, 6))
    ax = sns.countplot(data=df, x=column, order=counts.index)

    total = len(df)
    for i, p in enumerate(ax.patches):
        height = p.get_height()
        ax.text(p.get_x() + p.get_width() / 2.,
                height + 0.5,
                f'{percentages[i]:.2f}%',
                ha="center")

    plt.title(f'Count plot of {column} with Percentage')
    plt.xlabel(column)
    plt.ylabel('Count')

    plt.tight_layout()
    plt.show()

plot_categorical_percentage(df, 'Department')

sns.countplot(x='Attrition', data=df)
counts = df['Attrition'].value_counts()
total = counts.sum()

for bar, count in zip(plt.gca().patches, counts):
    height = bar.get_height()
    percentage = (count / total) * 100
    plt.text(bar.get_x() + bar.get_width() / 2, height + 0.1, f"{round((100-percentage),2)}%", ha='center', va='bottom')

plt.xlabel('Attrition')
plt.ylabel('Count')
plt.title('Attrition Frequency')

plt.show()

def plot_categorical_vs_attrition(df, categorical_columns):
    for column in categorical_columns:
        data_count = df.groupby([column, 'Attrition']).size().reset_index(name='n')

        plt.figure(figsize=(10, 6))
        sns.barplot(data=data_count, x=column, y='n', hue='Attrition', ci=None, palette=["#007bff", "#ffa500"])

        plt.xticks(rotation=45, ha='right')

        plt.title(f'Attrition by {column}')
        plt.xlabel(column)
        plt.ylabel('Count')

        plt.tight_layout()
        plt.show()

categorical_columns = ['Department', 'JobRole', 'EducationField', 'Gender', 'MaritalStatus', 'Over18', 'OverTime']
plot_categorical_vs_attrition(df, categorical_columns)

plt.figure(figsize=(10, 6))
sns.boxplot(data=df, x='Attrition', y='DistanceFromHome')

plt.title('Attrition vs. Distance From Home')
plt.xlabel('Attrition')
plt.ylabel('Distance From Home')

plt.tight_layout()
plt.show()

plt.figure(figsize=(10, 6))
sns.boxplot(data=df, x='Attrition', y='Age')

plt.title('Attrition vs. Age')
plt.xlabel('Attrition')
plt.ylabel('Age')

plt.tight_layout()
plt.show()

plt.figure(figsize=(10, 6))
sns.boxplot(data=df, x='Attrition', y='YearsInCurrentRole')

plt.title('Attrition vs. YearsInCurrentRole')
plt.xlabel('Attrition')
plt.ylabel('YearsInCurrentRole')

plt.tight_layout()
plt.show()

plt.figure(figsize=(10, 6))
sns.boxplot(data=df, x='Attrition', y='PercentSalaryHike')

plt.title('Attrition vs. PercentSalaryHike')
plt.xlabel('Attrition')
plt.ylabel('PercentSalaryHike')

plt.tight_layout()
plt.show()

plt.figure(figsize=(10, 6))
sns.boxplot(data=df, x='Attrition', y='YearsWithCurrManager')

plt.title('Attrition vs. YearsWithCurrManager')
plt.xlabel('Attrition')
plt.ylabel('YearsWithCurrManager')

plt.tight_layout()
plt.show()

feature = 'JobRole'
target_feature = 'Attrition'
data = df[[feature, target_feature]]

counts = data.groupby([feature, target_feature]).size().unstack(fill_value=0)
total_counts = counts.sum(axis=1)

proportions = counts.div(total_counts, axis=0)

ax = proportions.plot(kind='bar', stacked=True, figsize=(12, 6))
ax.set_title(f"{feature} vs. {target_feature}")
ax.set_ylabel("Proportion")
ax.set_xlabel(feature)

plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

"""Handling Outliers"""

def handle_outliers_iqr(data, numerical_features, threshold=1.5):
    data_no_outliers = data.copy()

    for feature in numerical_features:
        Q1 = data[feature].quantile(0.25)
        Q3 = data[feature].quantile(0.75)
        IQR = Q3 - Q1

        lower_bound = Q1 - threshold * IQR
        upper_bound = Q3 + threshold * IQR

        data_no_outliers.loc[(data_no_outliers[feature] < lower_bound) | (data_no_outliers[feature] > upper_bound), feature] = data_no_outliers[feature].median()

    return data_no_outliers


df = handle_outliers_iqr(df, numerical_features)

"""Handling Missing Values"""

df.isnull().sum()

"""Scaling Numerical Features"""

def scale_numerical_features(data, numerical_features):
    scaler = StandardScaler()
    data_scaled = data.copy()
    data_scaled[numerical_features] = scaler.fit_transform(data_scaled[numerical_features])
    return data_scaled, scaler

df, scaler = scale_numerical_features(df, numerical_features)

"""Handling Categorical Features"""

categorical_features = ['BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus', 'Over18', 'OverTime']
df = pd.get_dummies(df, columns=categorical_features, drop_first=True)

#Label Encoding for the target variable 'Attrition'
label_encoder = LabelEncoder()
df['Attrition'] = label_encoder.fit_transform(df['Attrition'])

df.head()

"""Model Development"""

X = df.drop('Attrition', axis=1)
y = df['Attrition']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

logistic_model = LogisticRegression(max_iter=1000)
logistic_model.fit(X_train, y_train)

train_predictions = logistic_model.predict(X_train)
test_predictions = logistic_model.predict(X_test)

# Accuracy
train_accuracy = accuracy_score(y_train, train_predictions)
test_accuracy = accuracy_score(y_test, test_predictions)

# Precision
train_precision = precision_score(y_train, train_predictions)
test_precision = precision_score(y_test, test_predictions)

# Recall
train_recall = recall_score(y_train, train_predictions)
test_recall = recall_score(y_test, test_predictions)

# F1-score
train_f1 = f1_score(y_train, train_predictions)
test_f1 = f1_score(y_test, test_predictions)

print("Training set metrics:")
print("Accuracy:", train_accuracy)
print("Precision:", train_precision)
print("Recall:", train_recall)
print("F1-score:", train_f1)
print()
print("Testing set metrics:")
print("Accuracy:", test_accuracy)
print("Precision:", test_precision)
print("Recall:", test_recall)
print("F1-score:", test_f1)

# Evaluation metrics
accuracy = accuracy_score(y_test, test_predictions)
precision = precision_score(y_test, test_predictions)
recall = recall_score(y_test, test_predictions)
f1 = f1_score(y_test, test_predictions)
conf_matrix = confusion_matrix(y_test, test_predictions)

print("Model Evaluation Metrics:")
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1-score:", f1)
print("Confusion Matrix:\n", conf_matrix)

fpr, tpr, _ = roc_curve(y_test, test_predictions)
roc_auc = auc(fpr, tpr)

plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

"""Hyperparameter Tuning of the Model"""

model = logistic_model
solvers = ['newton-cg', 'lbfgs', 'liblinear', 'saga']
penalty = ['l2']
c_values = [100, 10, 1.0, 0.1, 0.01]

grid = dict(solver=solvers,penalty=penalty,C=c_values)
grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, scoring='accuracy',error_score=0)
grid_result = grid_search.fit(X, y)

print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
    print("%f (%f) with: %r" % (mean, stdev, param))

best_solver = grid_result.best_params_['solver']
best_penalty = grid_result.best_params_['penalty']
best_C = grid_result.best_params_['C']

best_logistic_model = LogisticRegression(solver=best_solver, penalty=best_penalty, C=best_C)
best_logistic_model.fit(X, y)
y_pred = best_logistic_model.predict(X)

accuracy = accuracy_score(y, y_pred)
precision = precision_score(y, y_pred)
recall = recall_score(y, y_pred)
f1 = f1_score(y, y_pred)

print("Optimized Model Performance:")
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1-score:", f1)

with open('optimized_logistic_regression_model.pkl', 'wb') as file:
    pickle.dump(best_logistic_model, file) # To save the model

# To Load the model
# with open('optimized_logistic_regression_model.pkl', 'rb') as file:
#     loaded_model = pickle.load(file)